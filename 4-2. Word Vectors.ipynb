{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pretrained word-embedding (word2vec, glove or fasttext) for featurization instead of the\n",
    "bag-of-words model. Does this improve classification? How about combining the embedded\n",
    "words with the BoW model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wjdos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winemag-data-130k-v2.csv')\n",
    "df = df[df['country'] == 'US']\n",
    "df_sample = df.sample(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg', disable = ['tagger', 'parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        price            designation    province              region_1  \\\n",
      "26502    18.0   Estate Grown Rosé of  California  Russian River Valley   \n",
      "29465    18.0                    NaN  Washington  Columbia Valley (WA)   \n",
      "61303    12.0                    NaN  California                  Lodi   \n",
      "128905   30.0    Zena Crown Vineyard      Oregon      Eola-Amity Hills   \n",
      "25468    32.0                    NaN  California           Edna Valley   \n",
      "...       ...                    ...         ...                   ...   \n",
      "35993    38.0        Smith Vineyards  California      Dry Creek Valley   \n",
      "115025   14.0               Demi-Sec     America                   NaN   \n",
      "98923    50.0           Cuvée Moriah  California         Sonoma County   \n",
      "44347    40.0  Tephra Ridge Vineyard  California           Lake County   \n",
      "68732    48.0   Essence Estate Grown  California           Napa Valley   \n",
      "\n",
      "                 region_2                variety     taster_name  \\\n",
      "26502              Sonoma             Pinot Noir  Virginie Boone   \n",
      "29465     Columbia Valley               Riesling    Paul Gregutt   \n",
      "61303      Central Valley              Zinfandel      Jim Gordon   \n",
      "128905  Willamette Valley             Pinot Noir    Paul Gregutt   \n",
      "25468       Central Coast             Pinot Noir             NaN   \n",
      "...                   ...                    ...             ...   \n",
      "35993              Sonoma               Grenache  Virginie Boone   \n",
      "115025                NaN               Vignoles             NaN   \n",
      "98923              Sonoma  Rhône-style Red Blend  Virginie Boone   \n",
      "44347                 NaN                 Merlot             NaN   \n",
      "68732                Napa        Sauvignon Blanc             NaN   \n",
      "\n",
      "                                                     text  \n",
      "26502   This is a richer, rounder version of rosé, wit...  \n",
      "29465   Fruity and full-flavored, this quaffable Riesl...  \n",
      "61303   Mouthwatering fruit flavors and a firm, dry mo...  \n",
      "128905  Arresting from the get-go, with a spice-driven...  \n",
      "25468   A cheerful Pinot Noir, rich and silky, and per...  \n",
      "...                                                   ...  \n",
      "35993   This wine is an intrigue of lavender, rose and...  \n",
      "115025  This has striking aromas of passion fruit, apr...  \n",
      "98923   A Chateauneuf-du-Pape inspired blend of 64% Gr...  \n",
      "44347   Easily the best Merlot in memory from Lake Cou...  \n",
      "68732   After years of tinkering with Sauvignon Blanc,...  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "X_col = ['price','designation', 'province', 'region_1','region_2','variety', 'taster_name',\n",
    "        'text']\n",
    "cont = ['price']\n",
    "cat = ['designation', 'province', 'region_1','region_2','variety', 'taster_name']\n",
    "text = ['text']\n",
    "\n",
    "df_sample[\"text\"] =  df_sample['description']+ df_sample['title'] + df_sample['winery']\n",
    "\n",
    "y = df_sample['points']\n",
    "X = df_sample.loc[:, X_col]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning (punctuations, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text_train = X_train.text.str.lower()\n",
    "text_test = X_test.text.str.lower()\n",
    "\n",
    "#remove punctuations\n",
    "text_train = text_train.apply((lambda x : re.sub(\"[^a-z0-9\\s]\",\"\",x)) )\n",
    "text_test = text_test.apply((lambda x : re.sub(\"[^a-z0-9\\s]\",\"\",x)) )\n",
    "\n",
    "#remove stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "text_train = text_train.apply(lambda x : \" \".join(w for w in x.split() if w not in stopwords))\n",
    "text_test = text_test.apply(lambda x : \" \".join(w for w in x.split() if w not in stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           text0     text1     text2     text3     text4     text5     text6  \\\n",
      "20419  -0.155254  0.146008 -0.070758 -0.215490  0.125964  0.042638  0.065526   \n",
      "46710  -0.104202  0.204439 -0.097630 -0.225781  0.174469  0.039809  0.073507   \n",
      "80685  -0.070993  0.014188  0.072261 -0.233255  0.121731  0.148858  0.021181   \n",
      "2900   -0.032034 -0.015748 -0.034118 -0.039829  0.148092  0.081990  0.060652   \n",
      "88860  -0.159887  0.166690  0.012707 -0.202276  0.169835  0.157067  0.077961   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "5738   -0.077434  0.133818  0.021649 -0.313426  0.190623  0.198321  0.061229   \n",
      "109737  0.006986  0.119540  0.045174 -0.036015  0.219111  0.015925 -0.060145   \n",
      "51247  -0.149211  0.115970  0.009654 -0.072114  0.085058  0.011927  0.016982   \n",
      "100687  0.033715  0.103318 -0.028462 -0.155140  0.177353  0.243839 -0.044566   \n",
      "48960  -0.085270  0.130056  0.068531 -0.162478  0.152720  0.120353 -0.020313   \n",
      "\n",
      "           text7     text8     text9  ...   text290   text291   text292  \\\n",
      "20419   0.127679 -0.031813  1.240153  ... -0.044815  0.159116 -0.159369   \n",
      "46710   0.153822 -0.069761  1.085119  ... -0.065441  0.142460 -0.094717   \n",
      "80685   0.236205 -0.032798  0.819900  ... -0.063518  0.239394 -0.147301   \n",
      "2900   -0.041422  0.060895  1.054176  ... -0.011186  0.119418 -0.267812   \n",
      "88860   0.072673 -0.072598  0.695058  ... -0.049047  0.185764 -0.198473   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "5738    0.107766  0.005990  0.945636  ... -0.080490  0.184347 -0.180873   \n",
      "109737  0.111535 -0.071538  0.678675  ... -0.012153  0.132054 -0.155590   \n",
      "51247   0.043126 -0.072771  0.967322  ... -0.025715  0.126603 -0.154528   \n",
      "100687  0.161155 -0.037069  0.659379  ...  0.070179  0.124825 -0.142808   \n",
      "48960   0.112611  0.009450  0.328624  ...  0.083814  0.198204 -0.148289   \n",
      "\n",
      "         text293   text294   text295   text296   text297   text298   text299  \n",
      "20419  -0.052937 -0.059257 -0.064620  0.156712 -0.234759 -0.001318  0.044337  \n",
      "46710  -0.045457 -0.057009 -0.005890  0.109221 -0.304006  0.053196  0.043022  \n",
      "80685  -0.124172 -0.250455 -0.007925  0.211481 -0.215198 -0.107558 -0.008962  \n",
      "2900   -0.034941 -0.151637 -0.121301  0.169758 -0.272572  0.086522 -0.023162  \n",
      "88860  -0.017870 -0.184658 -0.113986  0.125544 -0.211241 -0.020809  0.085605  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "5738   -0.029398 -0.257112 -0.204014  0.058542 -0.304150  0.000880 -0.053981  \n",
      "109737 -0.085941 -0.128398 -0.019638  0.034399 -0.175930  0.136134  0.040394  \n",
      "51247  -0.066573  0.021211 -0.125176  0.058227 -0.261873  0.058225  0.050466  \n",
      "100687 -0.094500 -0.197835 -0.021305  0.158180 -0.222329 -0.018300 -0.027640  \n",
      "48960  -0.077402 -0.242409 -0.107001  0.077489 -0.270876  0.064474 -0.050596  \n",
      "\n",
      "[750 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "docs_train_text =  [nlp(d).vector for d in text_train]\n",
    "docs_test_text = [nlp(d).vector for d in text_test]\n",
    "\n",
    "\n",
    "X_train_word2vec = np.vstack(docs_train_text)\n",
    "X_test_word2vec = np.vstack(docs_test_text)\n",
    "\n",
    "\n",
    "X_train_word2vec = pd.DataFrame(X_train_word2vec)\n",
    "X_train_word2vec.index = X_train.index\n",
    "\n",
    "# print(X_train_word2vec)\n",
    "\n",
    "X_test_word2vec = pd.DataFrame(X_test_word2vec)\n",
    "X_test_word2vec.index = X_test.index\n",
    "\n",
    "X_train_word2vec.columns = ['text'+str(i) for i in range(300)]\n",
    "X_test_word2vec.columns = ['text'+str(i) for i in range(300)]\n",
    "\n",
    "print(X_train_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression mean cv score with text data (Word Embedding only) : 0.49388929483317956\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression mean cv score with text data (Word Embedding only) :\", np.mean(cross_val_score(LinearRegression(), X_train_word2vec, y_train, cv = 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding + cont&cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       price                           designation    province  \\\n",
      "20419   40.0  Estate Wine Middleton Petty Vineyard  Washington   \n",
      "46710   21.0                           Crazy Creek  California   \n",
      "80685   24.0                 The Hill and the Vale  California   \n",
      "2900    40.0                         Amber's Cuvee  California   \n",
      "88860   60.0                          La Rinconada  California   \n",
      "\n",
      "                      region_1         region_2             variety  \\\n",
      "20419  Walla Walla Valley (WA)  Columbia Valley              Merlot   \n",
      "46710         Alexander Valley           Sonoma  Cabernet Sauvignon   \n",
      "80685            Sonoma County           Sonoma           Zinfandel   \n",
      "2900      Santa Cruz Mountains    Central Coast     Sparkling Blend   \n",
      "88860          Sta. Rita Hills    Central Coast          Pinot Noir   \n",
      "\n",
      "            taster_name                                               text  \\\n",
      "20419  Sean P. Sullivan  The aromas show notes of chocolate and raspber...   \n",
      "46710               NaN  This is really one of the best values in Caber...   \n",
      "80685    Virginie Boone  Co-fermented with 10% Petite Sirah, this red c...   \n",
      "2900      Matt Kettmann  A faint hint of pink shines on this sparkler n...   \n",
      "88860               NaN  There's a grace and purity to this Pinot Noir ...   \n",
      "\n",
      "          text0     text1  ...   text290   text291   text292   text293  \\\n",
      "20419 -0.155254  0.146008  ... -0.044815  0.159116 -0.159369 -0.052937   \n",
      "46710 -0.104202  0.204439  ... -0.065441  0.142460 -0.094717 -0.045457   \n",
      "80685 -0.070993  0.014188  ... -0.063518  0.239394 -0.147301 -0.124172   \n",
      "2900  -0.032034 -0.015748  ... -0.011186  0.119418 -0.267812 -0.034941   \n",
      "88860 -0.159887  0.166690  ... -0.049047  0.185764 -0.198473 -0.017870   \n",
      "\n",
      "        text294   text295   text296   text297   text298   text299  \n",
      "20419 -0.059257 -0.064620  0.156712 -0.234759 -0.001318  0.044337  \n",
      "46710 -0.057009 -0.005890  0.109221 -0.304006  0.053196  0.043022  \n",
      "80685 -0.250455 -0.007925  0.211481 -0.215198 -0.107558 -0.008962  \n",
      "2900  -0.151637 -0.121301  0.169758 -0.272572  0.086522 -0.023162  \n",
      "88860 -0.184658 -0.113986  0.125544 -0.211241 -0.020809  0.085605  \n",
      "\n",
      "[5 rows x 308 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.join(X_train_word2vec)\n",
    "X_test = X_test.join(X_test_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression mean cv score with Word Embedding only : 0.40997952075468724\n"
     ]
    }
   ],
   "source": [
    "#drop description and title in original dataframe\n",
    "#cat+cont and Wordembedding method\n",
    "\n",
    "X_train_we = X_train.drop(text,axis = 1)\n",
    "X_test_we =X_test.drop(text, axis=1)\n",
    "\n",
    "cat_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy ='constant', fill_value = 'NA'),\n",
    "    OneHotEncoder(handle_unknown = 'ignore')\n",
    "    )\n",
    "\n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler()\n",
    "    )\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cat_preprocessing', cat_preprocessing, cat),\n",
    "        ('cont_preprocessing', cont_preprocessing, cont)\n",
    "    ],\n",
    "    remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "OLS_pipe = make_pipeline(preprocess, LinearRegression())\n",
    "print(\"Linear Regression mean cv score with Word Embedding only :\", np.mean(cross_val_score(OLS_pipe, X_train_we, y_train, cv = 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding with BoW(CountVectorizer) + cont/cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression mean cv score: 0.5615841091261851\n"
     ]
    }
   ],
   "source": [
    "#Word embedding with BoW on text data\n",
    "#Linear Regression\n",
    "cat_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy ='constant', fill_value = 'NA'),\n",
    "    OneHotEncoder(handle_unknown = 'ignore')\n",
    "    )\n",
    "\n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler()\n",
    "    )\n",
    "\n",
    "text_preprocessing = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1,3))\n",
    "    )\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (cont_preprocessing, cont),\n",
    "    (cat_preprocessing, cat),\n",
    "    (text_preprocessing, 'text'))\n",
    "\n",
    "\n",
    "\n",
    "OLS_pipe = make_pipeline(preprocess, LinearRegression())\n",
    "print(\"Linear Regression mean cv score:\", np.mean(cross_val_score(OLS_pipe, X_train, y_train, cv = 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding with BoW(TfidfVectorizer) + cont/cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression mean cv score: 0.5660923944673193\n"
     ]
    }
   ],
   "source": [
    "#Word embedding with BoW on text data\n",
    "#Linear Regression\n",
    "cat_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy ='constant', fill_value = 'NA'),\n",
    "    OneHotEncoder(handle_unknown = 'ignore')\n",
    "    )\n",
    "\n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler()\n",
    "    )\n",
    "\n",
    "text_preprocessing = make_pipeline(\n",
    "    TfidfVectorizer(ngram_range=(1,3))\n",
    "    )\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (cont_preprocessing, cont),\n",
    "    (cat_preprocessing, cat),\n",
    "    (text_preprocessing, 'text')\n",
    ")\n",
    "\n",
    "\n",
    "OLS_pipe = make_pipeline(preprocess, LinearRegression())\n",
    "print(\"Linear Regression mean cv score:\", np.mean(cross_val_score(OLS_pipe, X_train, y_train, cv = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge mean cv score : 0.5434777633630656\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "Ridge_pipe = make_pipeline(preprocess, Ridge())\n",
    "\n",
    "print(\"Ridge mean cv score :\", np.mean(cross_val_score(Ridge_pipe, X_train, y_train, cv = 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge mean on whole data cv score : 0.7848556793672598\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "X_col = ['price','designation', 'province', 'region_1','region_2','variety', 'taster_name',\n",
    "        'text']\n",
    "cont = ['price']\n",
    "cat = ['designation', 'province', 'region_1','region_2','variety', 'taster_name']\n",
    "text = ['text']\n",
    "\n",
    "df[\"text\"] =  df['description']+ df['title'] + df['winery']\n",
    "\n",
    "y = df['points']\n",
    "X = df.loc[:, X_col]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "text_train = X_train.text.str.lower()\n",
    "text_test = X_test.text.str.lower()\n",
    "\n",
    "#remove punctuations\n",
    "text_train = text_train.apply((lambda x : re.sub(\"[^a-z0-9\\s]\",\"\",x)) )\n",
    "text_test = text_test.apply((lambda x : re.sub(\"[^a-z0-9\\s]\",\"\",x)) )\n",
    "\n",
    "#remove stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "text_train = text_train.apply(lambda x : \" \".join(w for w in x.split() if w not in stopwords))\n",
    "text_test = text_test.apply(lambda x : \" \".join(w for w in x.split() if w not in stopwords))\n",
    "\n",
    "docs_train_text =  [nlp(d).vector for d in text_train]\n",
    "docs_test_text = [nlp(d).vector for d in text_test]\n",
    "\n",
    "X_train_word2vec = np.vstack(docs_train_text)\n",
    "X_test_word2vec = np.vstack(docs_test_text)\n",
    "\n",
    "X_train_word2vec = pd.DataFrame(X_train_word2vec)\n",
    "X_train_word2vec.index = X_train.index\n",
    "\n",
    "X_test_word2vec = pd.DataFrame(X_test_word2vec)\n",
    "X_test_word2vec.index = X_test.index\n",
    "\n",
    "X_train_word2vec.columns = ['text'+str(i) for i in range(300)]\n",
    "X_test_word2vec.columns = ['text'+str(i) for i in range(300)]\n",
    "\n",
    "cat_preprocessing = make_pipeline(\n",
    "    SimpleImputer(strategy ='constant', fill_value = 'NA'),\n",
    "    OneHotEncoder(handle_unknown = 'ignore')\n",
    "    )\n",
    "\n",
    "cont_preprocessing = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler()\n",
    "    )\n",
    "\n",
    "text_preprocessing = make_pipeline(\n",
    "    CountVectorizer(ngram_range=(1,3))\n",
    "    )\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (cont_preprocessing, cont),\n",
    "    (cat_preprocessing, cat),\n",
    "    (text_preprocessing, 'text')\n",
    ")\n",
    "\n",
    "Ridge_pipe = make_pipeline(preprocess, Ridge())\n",
    "\n",
    "print(\"Ridge mean on whole data cv score :\", np.mean(cross_val_score(Ridge_pipe, X_train, y_train, cv = 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
